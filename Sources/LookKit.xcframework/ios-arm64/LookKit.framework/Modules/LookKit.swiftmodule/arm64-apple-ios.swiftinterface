// swift-interface-format-version: 1.0
// swift-compiler-version: Apple Swift version 5.3.2 (swiftlang-1200.0.45 clang-1200.0.32.28)
// swift-module-flags: -target arm64-apple-ios13.0 -enable-objc-interop -enable-library-evolution -swift-version 5 -enforce-exclusivity=checked -O -module-name LookKit
import Accelerate
import CoreML
import Foundation
@_exported import LookKit
import Photos
import Swift
import UIKit
import Vision
import simd
public enum ClusterType {
  case DBSCAN
  case ChineseWhispers
  public static func == (a: LookKit.ClusterType, b: LookKit.ClusterType) -> Swift.Bool
  public var hashValue: Swift.Int {
    get
  }
  public func hash(into hasher: inout Swift.Hasher)
}
public struct ClusterOptions {
  public init(minimumClusterSize: Swift.Int = 1, numberIterations: Swift.Int = 100, faceSimilarityThreshold: Swift.Double = 0.7, clusterType: LookKit.ClusterType = .ChineseWhispers)
}
@_hasMissingDesignatedInitializers public class ImageProcessor {
  public static func alignFaces(from sourceImage: UIKit.UIImage, processConfiguration: LookKit.ProcessConfiguration, completion: @escaping (Swift.Result<[LookKit.Face], LookKit.VisionProcessError>) -> Swift.Void)
  public static func alignFaces(fetchOptions: LookKit.AssetFetchingOptions, processConfiguration: LookKit.ProcessConfiguration, completion: @escaping (Swift.Result<[LookKit.Face], LookKit.VisionProcessError>) -> Swift.Void)
  @objc deinit
}
public enum VisionProcessError : Swift.Error {
  case unknown
  case fetchImages
  case facesDetcting
  case cgImageNotFound
  case emptyObservation
  case error(Swift.Error)
}
public class AssetFetchingOptions {
  public init(sortDescriptors: [Foundation.NSSortDescriptor]? = nil, assetCollection: LookKit.AssetCollection = .allAssets, fetchLimit: Swift.Int = Int.max)
  @objc deinit
}
@_hasMissingDesignatedInitializers public class Recognition {
  public static func cluster(fetchOptions: LookKit.AssetFetchingOptions, culsterOptions: LookKit.ClusterOptions, processConfiguration: LookKit.ProcessConfiguration = ProcessConfiguration(), completion: @escaping (Swift.Result<[[LookKit.Face]], LookKit.VisionProcessError>) -> Swift.Void)
  public static func compareFaces(sourceImage: UIKit.UIImage, targetImage: UIKit.UIImage, similarityThreshold: Swift.Double, processConfiguration: LookKit.ProcessConfiguration = ProcessConfiguration(), completion: @escaping (Swift.Result<(result: Swift.Bool, distance: Swift.Double), LookKit.FaceComparisonError>) -> Swift.Void)
  @objc deinit
}
public struct ProcessOutput : Swift.Hashable {
  public let localIdentifier: Swift.String
  public let tags: [LookKit.DetectedObject]
  public let boundingBoxes: [CoreGraphics.CGRect]
  public let faces: [LookKit.Face]
  public func hash(into hasher: inout Swift.Hasher)
  public var hashValue: Swift.Int {
    get
  }
  public static func == (a: LookKit.ProcessOutput, b: LookKit.ProcessOutput) -> Swift.Bool
}
public enum PhotosAuthorizationError : Swift.Error {
  case denied
  case notDetermined
  public static func == (a: LookKit.PhotosAuthorizationError, b: LookKit.PhotosAuthorizationError) -> Swift.Bool
  public var hashValue: Swift.Int {
    get
  }
  public func hash(into hasher: inout Swift.Hasher)
}
public typealias VisionFilter = (LookKit.ProcessInput) throws -> LookKit.ProcessInput
@_hasMissingDesignatedInitializers public class VFilter {
  public static func faceRectangle() -> LookKit.VisionFilter
  public static func objectDetecting() -> LookKit.VisionFilter
  public static func imageQuality() -> LookKit.VisionFilter
  public static func faceEmbedding() -> LookKit.VisionFilter
  @objc deinit
}
public class ImageFetcherService {
  public init(options: LookKit.ImageFetcherOptions = ImageFetcherOptions())
  public func image(from identifier: Swift.String) -> UIKit.UIImage?
  @objc deinit
}
@_hasMissingDesignatedInitializers public class Defaults {
  public static let shared: LookKit.Defaults
  public var print: Swift.Bool
  @objc deinit
}
@_hasMissingDesignatedInitializers public class Detector {
  public static func detect(_ pipe: @escaping LookKit.VisionFilter, with options: LookKit.AssetFetchingOptions, processConfiguration: LookKit.ProcessConfiguration = ProcessConfiguration(), completion: @escaping (Swift.Result<[LookKit.ProcessOutput], LookKit.VisionProcessError>) -> Swift.Void)
  public static func detect(_ pipe: @escaping LookKit.VisionFilter, sourceImage: UIKit.UIImage, processConfiguration: LookKit.ProcessConfiguration = ProcessConfiguration(), completion: @escaping (Swift.Result<[LookKit.ProcessOutput], LookKit.VisionProcessError>) -> Swift.Void)
  @objc deinit
}
extension PHImageRequestOptions {
  public static var defaultOptions: Photos.PHImageRequestOptions {
    get
  }
}
public struct ProcessInput {
}
public struct ProcessAsset {
}
public struct FaceClusters {
  public let faceID: Swift.Int
  public let faces: [LookKit.Face]
}
public enum VisionProcessType {
  case imageFatching
  case faceDetection
  case objectDetection
  case imageQuality
  public static func == (a: LookKit.VisionProcessType, b: LookKit.VisionProcessType) -> Swift.Bool
  public var hashValue: Swift.Int {
    get
  }
  public func hash(into hasher: inout Swift.Hasher)
}
public class ProcessConfiguration {
  public init()
  public var imageSize: CoreGraphics.CGFloat
  public enum FeaturePoints {
    case points76
    case pointsDlib5
    case pointsSphereFace5
    public static func == (a: LookKit.ProcessConfiguration.FeaturePoints, b: LookKit.ProcessConfiguration.FeaturePoints) -> Swift.Bool
    public var hashValue: Swift.Int {
      get
    }
    public func hash(into hasher: inout Swift.Hasher)
  }
  public var minimumFaceArea: CoreGraphics.CGFloat
  public var minimumFeaturePointsConfidance: Swift.Float
  public var featurePointsAlgorithm: LookKit.ProcessConfiguration.FeaturePoints
  public var faceSize: Swift.Double
  public var facePadding: Swift.Double
  public var qualityFilter: LookKit.QualityFilter
  public var drawFeaturePoints: Swift.Bool
  public var print: Swift.Bool
  @objc deinit
}
@_hasMissingDesignatedInitializers public class PhotosAuthorizationService {
  public static func checkPhotoLibraryPermission(completion: @escaping (Swift.Result<Swift.Void, LookKit.PhotosAuthorizationError>) -> Swift.Void)
  @objc deinit
}
precedencegroup ComparisonPrecedence {
  associativity: left
}
infix operator |> : ComparisonPrecedence
infix operator >> : ComparisonPrecedence
infix operator --> : ComparisonPrecedence
public func --> <U, T, Z>(f: @escaping (U) throws -> T, g: @escaping (T) throws -> Z) -> (U) throws -> (Z)
infix operator >>> : ComparisonPrecedence
public enum QualityFilter {
  case none
  case low
  case medium
  case high
  case extreme
  public static func == (a: LookKit.QualityFilter, b: LookKit.QualityFilter) -> Swift.Bool
  public var hashValue: Swift.Int {
    get
  }
  public func hash(into hasher: inout Swift.Hasher)
}
public struct Face : Swift.Hashable, Swift.Identifiable {
  public var id: Swift.String {
    get
  }
  public let localIdnetifier: Swift.String
  public let faceCroppedImage: UIKit.UIImage
  public var landmarks: Vision.VNFaceLandmarks2D? {
    get
  }
  public let quality: Swift.Float
  public let faceAngle: Swift.Double
  public func hash(into hasher: inout Swift.Hasher)
  public var hashValue: Swift.Int {
    get
  }
  public typealias ID = Swift.String
  public static func == (a: LookKit.Face, b: LookKit.Face) -> Swift.Bool
}
public struct DetectedObject : Swift.Equatable {
  public let identifier: Swift.String
  public let confidence: Swift.Float
  public static func == (a: LookKit.DetectedObject, b: LookKit.DetectedObject) -> Swift.Bool
}
public class ImageFetcherOptions {
  public init(downsampleImageSize: CoreGraphics.CGFloat = 400, rquestOptions: Photos.PHImageRequestOptions = PHImageRequestOptions.defaultOptions)
  @objc deinit
}
public struct SamplePair<T> where T : Swift.Comparable {
}
public struct OrderedSamplePair<T> {
}
public struct Pair<T> {
}
public struct Stack<Element> {
  public init()
  public mutating func push(_ element: Element)
  public mutating func pop() -> Element?
  public func peek() -> Element?
  public func isEmpty() -> Swift.Bool
}
public enum FaceComparisonError : Swift.Error {
  case tooManyFaces(Swift.Int)
  case cantFindFaces
  case error(Swift.Error)
}
public class ChineseWhisper {
  public init()
  public func cluster<T>(objects: [T], distanceFunction: (T, T) -> Swift.Double, eps: Swift.Double, numIterations: Swift.Int) -> [Swift.Int]
  public func cluster(edges: [LookKit.SamplePair<Swift.Int>], numIterations: Swift.Int) -> [Swift.Int]
  public func cluster(edges: [LookKit.OrderedSamplePair<Swift.Int>], numIterations: Swift.Int) -> [Swift.Int]
  public func group<T>(objects: [T], labels: [Swift.Int]) -> [[T]]
  @objc deinit
}
public struct DBScan {
  public init()
  public func cluster<Value>(values: [Value], epsilon: Swift.Double, minimumNumberOfPoints: Swift.Int, distanceFunction: (Value, Value) throws -> Swift.Double) rethrows -> [[Value]] where Value : Swift.Equatable
}
public enum AssetCollection {
  case allAssets
  case albumName(_: Swift.String)
  case assetCollection(_: Photos.PHAssetCollection)
  case identifiers(_: [Swift.String])
}
@_hasMissingDesignatedInitializers public class Cluster {
  public static let ChineseWhispers: LookKit.ChineseWhisper
  public static let DBSCAN: LookKit.DBScan
  @objc deinit
}
extension LookKit.ClusterType : Swift.Equatable {}
extension LookKit.ClusterType : Swift.Hashable {}
extension LookKit.PhotosAuthorizationError : Swift.Equatable {}
extension LookKit.PhotosAuthorizationError : Swift.Hashable {}
extension LookKit.VisionProcessType : Swift.Equatable {}
extension LookKit.VisionProcessType : Swift.Hashable {}
extension LookKit.ProcessConfiguration.FeaturePoints : Swift.Equatable {}
extension LookKit.ProcessConfiguration.FeaturePoints : Swift.Hashable {}
extension LookKit.QualityFilter : Swift.Equatable {}
extension LookKit.QualityFilter : Swift.Hashable {}
